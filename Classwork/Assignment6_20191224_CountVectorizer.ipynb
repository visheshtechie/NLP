{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment6_20191224_CountVectorizer",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visheshtechie/NLP/blob/master/Classwork/Assignment6_20191224_CountVectorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_8uxW4JesJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import string\n",
        "from string import digits\n",
        "from nltk.corpus import stopwords\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwuM2yuogdh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "eb0f75fe-9a6d-4c71-a013-91f019b182eb"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsbFeuIZjSD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading data\n",
        "tweet = pd.read_csv('https://raw.githubusercontent.com/zfz/twitter_corpus/master/full-corpus.csv', error_bad_lines=False)\n",
        "amazon = pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\", lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz_ulL0xgh5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing irrelevant sentiments in twitter data\n",
        "twitter = tweet[tweet['Sentiment']!='irrelevant']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YC9hihZg9ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toktoktok(text):\n",
        "  text= text.lower()\n",
        "  text = text.translate(text.maketrans('','',digits))#removing digits\n",
        "  text = text.translate(text.maketrans('', '', '!\"@#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'))\n",
        "  return text\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FktDo7sNm6Xr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "6eadf36c-3528-4dce-9076-f2797ea7a7f3"
      },
      "source": [
        "twitter['TweetTokens']= twitter['TweetText'].apply(toktoktok)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb6vmiIlm9Ym",
        "colab_type": "code",
        "outputId": "7554c38f-75fc-4b6b-e07c-1c7519b89be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "twitter['TweetTokens']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       now all apple has to do is get swype on the ip...\n",
              "1       apple will be adding more carrier support to t...\n",
              "2       hilarious youtube video  guy does a duet with ...\n",
              "3       rim you made it too easy for me to switch to a...\n",
              "4       i just realized that the reason i got into twi...\n",
              "                              ...                        \n",
              "4537    madtruckman modern day autograph i like the wa...\n",
              "4538     ways to use twitter for business httptcojyxko...\n",
              "4539    log off facebook on twitter  but i think im bo...\n",
              "4540         twitters dumb i dont like it  hush up justin\n",
              "4541    its almost  where is your bong is it packed le...\n",
              "Name: TweetTokens, Length: 3424, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT7QGYjettNx",
        "colab_type": "text"
      },
      "source": [
        "**CountVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMZ2ownxm-jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(lowercase=True, stop_words=set(stopwords.words('english')))\n",
        "X = vectorizer.fit_transform(twitter['TweetTokens'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB5kb-wvn8UH",
        "colab_type": "code",
        "outputId": "4dcec14e-5651-4ab4-dcd5-90012d48640c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "vectorizer.get_feature_names()[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aaa',\n",
              " 'aaargh',\n",
              " 'aac',\n",
              " 'aalkhubaizi',\n",
              " 'aapl',\n",
              " 'abandoned',\n",
              " 'abbas',\n",
              " 'abbreviations',\n",
              " 'ability',\n",
              " 'able']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sDPgZ_QoL-n",
        "colab_type": "code",
        "outputId": "addfcd56-d03a-44ab-94d6-6f6ab91966ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(X.toarray())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovUjDGfYrshY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1phZEY3r_DI",
        "colab_type": "code",
        "outputId": "f17bcb91-0c59-421b-81e7-861c67819e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "features.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaa</th>\n",
              "      <th>aaargh</th>\n",
              "      <th>aac</th>\n",
              "      <th>aalkhubaizi</th>\n",
              "      <th>aapl</th>\n",
              "      <th>abandoned</th>\n",
              "      <th>abbas</th>\n",
              "      <th>abbreviations</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>aboutthatlife</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>abstract</th>\n",
              "      <th>abt</th>\n",
              "      <th>acabo</th>\n",
              "      <th>academy</th>\n",
              "      <th>acappellamedia</th>\n",
              "      <th>acc</th>\n",
              "      <th>accelerate</th>\n",
              "      <th>accelerated</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>accent</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>access</th>\n",
              "      <th>accessibility</th>\n",
              "      <th>accessing</th>\n",
              "      <th>accessnetworks</th>\n",
              "      <th>accessories</th>\n",
              "      <th>accidently</th>\n",
              "      <th>accompanying</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accounts</th>\n",
              "      <th>acct</th>\n",
              "      <th>accumed</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accused</th>\n",
              "      <th>accusing</th>\n",
              "      <th>acha</th>\n",
              "      <th>achieved</th>\n",
              "      <th>...</th>\n",
              "      <th>yousendit</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youtubecomandroid</th>\n",
              "      <th>youtubeggbyvvuzs</th>\n",
              "      <th>youuuuuuuuuuuu</th>\n",
              "      <th>youve</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>ysi</th>\n",
              "      <th>yu</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yumyumyumi</th>\n",
              "      <th>yup</th>\n",
              "      <th>yuvalariav</th>\n",
              "      <th>yuvalz</th>\n",
              "      <th>yyc</th>\n",
              "      <th>yywhy</th>\n",
              "      <th>zaarly</th>\n",
              "      <th>zacksiam</th>\n",
              "      <th>zacksiezmagraff</th>\n",
              "      <th>zaibatsu</th>\n",
              "      <th>zappos</th>\n",
              "      <th>zdnet</th>\n",
              "      <th>zeggaramaboura</th>\n",
              "      <th>zero</th>\n",
              "      <th>zeroday</th>\n",
              "      <th>zetes</th>\n",
              "      <th>zite</th>\n",
              "      <th>zombiebomber</th>\n",
              "      <th>zomg</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zuckerberg</th>\n",
              "      <th>zug</th>\n",
              "      <th>zune</th>\n",
              "      <th>zzzzzzzzzzzz</th>\n",
              "      <th>версию</th>\n",
              "      <th>новую</th>\n",
              "      <th>представит</th>\n",
              "      <th>你好</th>\n",
              "      <th>透過</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8498 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aaa  aaargh  aac  aalkhubaizi  aapl  ...  версию  новую  представит  你好  透過\n",
              "0    0       0    0            0     0  ...       0      0           0   0   0\n",
              "1    0       0    0            0     0  ...       0      0           0   0   0\n",
              "2    0       0    0            0     0  ...       0      0           0   0   0\n",
              "3    0       0    0            0     0  ...       0      0           0   0   0\n",
              "4    0       0    0            0     0  ...       0      0           0   0   0\n",
              "\n",
              "[5 rows x 8498 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAz9eZdtsAMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test = tts(X,twitter['Sentiment'],test_size=0.3, random_state=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIezjYIy4R6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lala = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdLSK0F4sUoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = pd.DataFrame(X_train.toarray(),columns=vectorizer.get_feature_names())\n",
        "x_test = pd.DataFrame(X_test.toarray(),columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGsAtwh0uM_D",
        "colab_type": "text"
      },
      "source": [
        "**Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AI07gueuIeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ran = RandomForestClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8nmI_QyudVf",
        "colab_type": "code",
        "outputId": "6e362eff-4d92-4342-d58b-aec2d3ab210d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "ran.fit(x_train,y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyNvRCYnu5Kj",
        "colab_type": "code",
        "outputId": "08d22be2-2b46-4580-d082-fea69e87dda3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "y_pred = ran.predict(x_test)\n",
        "print(classification_report(ran.predict(x_test),y_test))#default threshold(0.5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.41      0.77      0.54        94\n",
            "     neutral       0.95      0.78      0.86       881\n",
            "    positive       0.22      0.53      0.31        53\n",
            "\n",
            "    accuracy                           0.77      1028\n",
            "   macro avg       0.53      0.69      0.57      1028\n",
            "weighted avg       0.86      0.77      0.80      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvaON1mU2VP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#roc auc score function\n",
        "def multiclass_roc_auc_score(y_test, y_pred, average='macro'):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  Y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred)\n",
        "  return roc_auc_score(Y_test, y_pred, average=average)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWHP9zd22sIb",
        "colab_type": "code",
        "outputId": "de054fa2-f7d3-4444-9dad-bf6102f5960a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "multiclass_roc_auc_score(y_test, y_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6488478808376842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gp5nkpb3Cz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "Y_test = le.fit_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2jhy6M-3GgI",
        "colab_type": "code",
        "outputId": "eccd339b-6cac-40ec-ba89-c53f86177755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "pred_ran = ran.predict_proba(x_test)\n",
        "pred_ran"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01      , 0.98857143, 0.00142857],\n",
              "       [0.        , 0.31      , 0.69      ],\n",
              "       [0.08      , 0.73      , 0.19      ],\n",
              "       ...,\n",
              "       [0.        , 0.83390662, 0.16609338],\n",
              "       [0.23      , 0.75      , 0.02      ],\n",
              "       [0.        , 0.92184035, 0.07815965]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6dJIriG3hut",
        "colab_type": "text"
      },
      "source": [
        "**LightGBM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U_ztIM4yNjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    \"objective\" : \"multiclass\",\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'multiclass',\n",
        "    'num_class':3,\n",
        "    'learning_rate':0.01,\n",
        "    'max_depth': 7,\n",
        "    'num_leaves': 127,\n",
        "    'feature_fraction': 0.4,\n",
        "    'bagging_freq': 10,\n",
        "    'num_iterations':1000 ,\n",
        "    'max_bin' : 32}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i6ev359yQuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()  \n",
        "d_train = lgb.Dataset(x_train,le.fit_transform(y_train))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FCWJBd-yWmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b92072c1-ec53-4364-f954-2c30892dfa16"
      },
      "source": [
        "clf = lgb.train( params,d_train, 100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km2uHUoNyklV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = clf.predict(x_test)\n",
        "best_preds= [np.argmax(line) for line in preds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DgMNdDsy6d5",
        "colab_type": "code",
        "outputId": "2e317c6b-1907-4f75-a478-97cfefc666aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.bincount((le.fit_transform(y_train)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 397, 1605,  394])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lufyTnQdy-SI",
        "colab_type": "code",
        "outputId": "21e4445f-6f33-4106-8c9b-bd2b76595311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(le.inverse_transform(best_preds),lala))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.25      0.56      0.34        77\n",
            "     neutral       0.94      0.75      0.83       922\n",
            "    positive       0.09      0.38      0.14        29\n",
            "\n",
            "    accuracy                           0.72      1028\n",
            "   macro avg       0.43      0.56      0.44      1028\n",
            "weighted avg       0.87      0.72      0.78      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olGAYpvy1sK4",
        "colab_type": "code",
        "outputId": "10ff5eec-da9c-4b2b-9189-66da6f4fd0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.bincount((best_preds))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 77, 922,  29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bufZ5Poo1xTS",
        "colab_type": "code",
        "outputId": "6532cfa2-014d-4fea-8ba8-a2713ec9f289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(classification_report(le.inverse_transform(best_preds_train),y_train))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.32      0.73      0.44       172\n",
            "     neutral       0.97      0.74      0.84      2101\n",
            "    positive       0.25      0.80      0.38       123\n",
            "\n",
            "    accuracy                           0.74      2396\n",
            "   macro avg       0.51      0.76      0.55      2396\n",
            "weighted avg       0.88      0.74      0.79      2396\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXfHFati44pq",
        "colab_type": "text"
      },
      "source": [
        "**Threshold = 0.6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmvjhG-b2CLy",
        "colab_type": "code",
        "outputId": "2643ae4b-0f53-4396-c271-2dd57b74156d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "###for lgbm\n",
        "\n",
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_1(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.6:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.6 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_1(preds)),y_train))\n",
        "      \n",
        "###For RandomForest\n",
        "pred_rf = ran.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(ran.predict(x_test),lala)))\n",
        "print(\"\\n 0.6 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_1(pred_rf)),lala) )"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.32      0.73      0.44       172\n",
            "     neutral       0.97      0.74      0.84      2101\n",
            "    positive       0.25      0.80      0.38       123\n",
            "\n",
            "    accuracy                           0.74      2396\n",
            "   macro avg       0.51      0.76      0.55      2396\n",
            "weighted avg       0.88      0.74      0.79      2396\n",
            "\n",
            "\n",
            " 0.6 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.12      0.85      0.21        55\n",
            "     neutral       0.84      0.82      0.83      1637\n",
            "    positive       0.59      0.33      0.43       704\n",
            "\n",
            "    accuracy                           0.68      2396\n",
            "   macro avg       0.52      0.67      0.49      2396\n",
            "weighted avg       0.75      0.68      0.70      2396\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.41      0.77      0.54        94\n",
            "     neutral       0.95      0.78      0.86       881\n",
            "    positive       0.22      0.53      0.31        53\n",
            "\n",
            "    accuracy                           0.77      1028\n",
            "   macro avg       0.53      0.69      0.57      1028\n",
            "weighted avg       0.86      0.77      0.80      1028\n",
            "\n",
            "\n",
            " 0.6 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.15      0.90      0.26        30\n",
            "     neutral       0.86      0.84      0.85       749\n",
            "    positive       0.50      0.25      0.34       249\n",
            "\n",
            "    accuracy                           0.70      1028\n",
            "   macro avg       0.51      0.66      0.48      1028\n",
            "weighted avg       0.75      0.70      0.71      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8MC-Og558mr",
        "colab_type": "text"
      },
      "source": [
        "**Threshold = 0.7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQXUoY-E5bn5",
        "colab_type": "code",
        "outputId": "096a3c1f-732b-458e-86b2-4dded180a0b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_2(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.7:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.7 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_2(preds)),y_train))\n",
        "      \n",
        "###For RandomForest\n",
        "pred_rf = ran.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(ran.predict(x_test),lala)))\n",
        "print(\"\\n 0.7 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_2(pred_rf)),lala) )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.32      0.73      0.44       172\n",
            "     neutral       0.97      0.74      0.84      2101\n",
            "    positive       0.25      0.80      0.38       123\n",
            "\n",
            "    accuracy                           0.74      2396\n",
            "   macro avg       0.51      0.76      0.55      2396\n",
            "weighted avg       0.88      0.74      0.79      2396\n",
            "\n",
            "\n",
            " 0.7 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.07      0.90      0.12        29\n",
            "     neutral       0.71      0.86      0.78      1327\n",
            "    positive       0.75      0.28      0.41      1040\n",
            "\n",
            "    accuracy                           0.61      2396\n",
            "   macro avg       0.51      0.68      0.44      2396\n",
            "weighted avg       0.72      0.61      0.61      2396\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.41      0.77      0.54        94\n",
            "     neutral       0.95      0.78      0.86       881\n",
            "    positive       0.22      0.53      0.31        53\n",
            "\n",
            "    accuracy                           0.77      1028\n",
            "   macro avg       0.53      0.69      0.57      1028\n",
            "weighted avg       0.86      0.77      0.80      1028\n",
            "\n",
            "\n",
            " 0.7 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.10      1.00      0.18        17\n",
            "     neutral       0.76      0.87      0.81       641\n",
            "    positive       0.70      0.24      0.35       370\n",
            "\n",
            "    accuracy                           0.64      1028\n",
            "   macro avg       0.52      0.70      0.45      1028\n",
            "weighted avg       0.73      0.64      0.64      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khCpe8LQ6gOU",
        "colab_type": "text"
      },
      "source": [
        "**Threshold = 0.8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtbp2Ufq6D6Z",
        "colab_type": "code",
        "outputId": "127596d0-d433-4d90-9a61-579a607b0b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_3(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.8:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.8 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_3(preds)),y_train))\n",
        "      \n",
        "###For RandomForest\n",
        "pred_rf = ran.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(ran.predict(x_test),lala)))\n",
        "print(\"\\n 0.8 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_3(pred_rf)),lala) )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.32      0.73      0.44       172\n",
            "     neutral       0.97      0.74      0.84      2101\n",
            "    positive       0.25      0.80      0.38       123\n",
            "\n",
            "    accuracy                           0.74      2396\n",
            "   macro avg       0.51      0.76      0.55      2396\n",
            "weighted avg       0.88      0.74      0.79      2396\n",
            "\n",
            "\n",
            " 0.8 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.03      0.85      0.05        13\n",
            "     neutral       0.42      0.92      0.58       737\n",
            "    positive       0.92      0.22      0.35      1646\n",
            "\n",
            "    accuracy                           0.44      2396\n",
            "   macro avg       0.46      0.66      0.33      2396\n",
            "weighted avg       0.76      0.44      0.42      2396\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.41      0.77      0.54        94\n",
            "     neutral       0.95      0.78      0.86       881\n",
            "    positive       0.22      0.53      0.31        53\n",
            "\n",
            "    accuracy                           0.77      1028\n",
            "   macro avg       0.53      0.69      0.57      1028\n",
            "weighted avg       0.86      0.77      0.80      1028\n",
            "\n",
            "\n",
            " 0.8 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.05      1.00      0.09         8\n",
            "     neutral       0.63      0.89      0.74       512\n",
            "    positive       0.78      0.19      0.31       508\n",
            "\n",
            "    accuracy                           0.55      1028\n",
            "   macro avg       0.48      0.69      0.38      1028\n",
            "weighted avg       0.70      0.55      0.52      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}